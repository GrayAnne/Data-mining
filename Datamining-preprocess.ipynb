{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19dbfd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f13ad02",
   "metadata": {},
   "source": [
    "We will use it to access the auto-mpg dataset. You can find this dataset on the UCI machine learning repository. For this class, we will use a version of the Auto MPG dataset, where I added column headers. You can find my version at https://data.heatonresearch.com/.\n",
    "\n",
    "UCI took this dataset from the StatLib library, which Carnegie Mellon University maintains. The dataset was used in the 1983 American Statistical Association Exposition. It contains data for 398 cars, including mpg, cylinders, displacement, horsepower , weight, acceleration, model year, origin and the car's name.\n",
    "\n",
    "The following code loads the MPG dataset into a data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "623b3946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  ...  year  origin                       name\n",
       "0  18.0          8         307.0  ...    70       1  chevrolet chevelle malibu\n",
       "1  15.0          8         350.0  ...    70       1          buick skylark 320\n",
       "2  18.0          8         318.0  ...    70       1         plymouth satellite\n",
       "3  16.0          8         304.0  ...    70       1              amc rebel sst\n",
       "4  17.0          8         302.0  ...    70       1                ford torino\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read data\n",
    "pd.set_option('display.max_columns', 7)\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/auto-mpg.csv\",na_values=['?'])#na_values:if data replace null as ? or others\n",
    "display(df[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41875e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy data, save original data\n",
    "df2=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "252995e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>...</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.514573</td>\n",
       "      <td>5.454774</td>\n",
       "      <td>193.425879</td>\n",
       "      <td>...</td>\n",
       "      <td>15.568090</td>\n",
       "      <td>76.010050</td>\n",
       "      <td>1.572864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.815984</td>\n",
       "      <td>1.701004</td>\n",
       "      <td>104.269838</td>\n",
       "      <td>...</td>\n",
       "      <td>2.757689</td>\n",
       "      <td>3.697627</td>\n",
       "      <td>0.802055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>104.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.175000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              mpg   cylinders  displacement  ...  acceleration        year  \\\n",
       "count  398.000000  398.000000    398.000000  ...    398.000000  398.000000   \n",
       "mean    23.514573    5.454774    193.425879  ...     15.568090   76.010050   \n",
       "std      7.815984    1.701004    104.269838  ...      2.757689    3.697627   \n",
       "min      9.000000    3.000000     68.000000  ...      8.000000   70.000000   \n",
       "25%     17.500000    4.000000    104.250000  ...     13.825000   73.000000   \n",
       "50%     23.000000    4.000000    148.500000  ...     15.500000   76.000000   \n",
       "75%     29.000000    8.000000    262.000000  ...     17.175000   79.000000   \n",
       "max     46.600000    8.000000    455.000000  ...     24.800000   82.000000   \n",
       "\n",
       "           origin  \n",
       "count  398.000000  \n",
       "mean     1.572864  \n",
       "std      0.802055  \n",
       "min      1.000000  \n",
       "25%      1.000000  \n",
       "50%      1.000000  \n",
       "75%      2.000000  \n",
       "max      3.000000  \n",
       "\n",
       "[8 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#distribution,statistical information\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62a6ba18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horsepower    392 non-null    float64\n",
      " 4   weight        398 non-null    int64  \n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   year          398 non-null    int64  \n",
      " 7   origin        398 non-null    int64  \n",
      " 8   name          398 non-null    object \n",
      "dtypes: float64(4), int64(4), object(1)\n",
      "memory usage: 28.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a032192",
   "metadata": {},
   "source": [
    "# Missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c520d16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      6\n",
       "weight          0\n",
       "acceleration    0\n",
       "year            0\n",
       "origin          0\n",
       "name            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing value\n",
    "df2.apply(lambda x: sum(x.isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dacb60",
   "metadata": {},
   "source": [
    "1. replace with median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "med = df['horsepower'].median()#mean\n",
    "df['horsepower'] = df['horsepower'].fillna(med)\n",
    "                 \n",
    "print(f\"horsepower has na? {pd.isnull(df['horsepower']).values.any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b1ffd4",
   "metadata": {},
   "source": [
    "2.drop the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd7a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame.dropna(*, axis=0, how=_NoDefault.no_default, thresh=_NoDefault.no_default, subset=None, inplace=False)\n",
    "df = df.dropna() # 0:row, 1:column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f57110",
   "metadata": {},
   "source": [
    "3.KNN：KNNImputer\n",
    "sklearn.impute.KNNImputer(*, missing_values=nan, n_neighbors=5, weights='uniform', metric='nan_euclidean', copy=True, add_indicator=False, keep_empty_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "imputer.fit_transform(df2)\n",
    "#can use selected columns\n",
    "#df2[['horsepower', 'mpg', 'year']] = imputer.fit_transform(df2f2[['horsepower', 'mpg', 'year']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe71440",
   "metadata": {},
   "source": [
    "4.Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aedf981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_numeric(df,current):\n",
    "    df_x=df.drop(current)\n",
    "    df_y = df[current]\n",
    "    #missing row\n",
    "    pred_mask = df[current].isnull()\n",
    "    train_mask = ~pred_mask\n",
    "    \n",
    "    x = df_x[train_mask].values\n",
    "    y = df_y[train_mask].values\n",
    "    \n",
    "    # Create train/test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(    \n",
    "        x, y, test_size=0.25, random_state=42)\n",
    "       \n",
    "    # Build the neural network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "    model.add(Dense(10, activation='relu')) # Hidden 2\n",
    "    model.add(Dense(1)) # Output\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "                            patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)\n",
    "    \n",
    "    # Prediction\n",
    "    x2 = df_x[pred_mask].values\n",
    "    pred = model.predict(x2)\n",
    "    \n",
    "    rtn = df.copy()\n",
    "    rtn.loc[pred_mask, current] = pred\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a880646",
   "metadata": {},
   "source": [
    "# outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ba22e",
   "metadata": {},
   "source": [
    "Outliers are values that are unusually high or low. We typically consider outliers to be a value that is several standard deviations from the mean. Sometimes outliers are simply errors; this is a result of observation error. Outliers can also be truly large or small values that may be difficult to address. The following function can remove such values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dfa1bf",
   "metadata": {},
   "source": [
    "Key points: define outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21522668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#ckeck outliers\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df2, orient=\"h\", palette=\"Set2\", dodge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean())\n",
    "                          >= (sd * df[name].std()))]\n",
    "    return drop_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac4ab0e",
   "metadata": {},
   "source": [
    "# feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1070ef91",
   "metadata": {},
   "source": [
    "You must drop fields that are of no value to the response value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeabd643",
   "metadata": {},
   "source": [
    "Simple Quality filtering\n",
    "\n",
    "• Missing values\n",
    "If a large fraction of your samples are missing data for a specific feature, just drop that feature\n",
    "If a large fraction of feature values are missing for a sample, just drop that sample\n",
    "\n",
    "• Low variance\n",
    "If a feature’s values are all the same, drop it\n",
    "\n",
    "• Domain expert judgement\n",
    "Does the feature make sense for the problem?\n",
    "Does the feature make sense for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24201269",
   "metadata": {},
   "source": [
    "Filter methods\n",
    "\n",
    "•Unsupervised approach\n",
    "If a pair of features or more are highly informative or predictive of each other, just keeping one as a representative is sufficient\n",
    "\n",
    "• Supervised approach\n",
    "If a feature is highly informative or predictive of the output, it’s more important\n",
    "\n",
    "• Scoring methods: mutual information, correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing values\n",
    "miss_rate_df = df.isnull().sum().sort_values(ascending=False) / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f46c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divergence\n",
    "# 分析方差 \n",
    "var_features = df.var().sort_values()\n",
    " \n",
    "# 特征单值率\n",
    "sigle_rate = {}\n",
    "for var in df.columns:\n",
    "    sigle_rate[var]=(df[var].value_counts().max()/df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af699bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#方差膨胀因子VIF：\n",
    "#方差膨胀因子也称为方差膨胀系数（Variance Inflation），用于计算数值特征间的共线性，一般当VIF大于10表示有较高共线性。\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# 截距项\n",
    "name = df.columns\n",
    "x = np.matrix(df)\n",
    "VIF_list = [variance_inflation_factor(x,i) for i in range(x.shape[1])]\n",
    "VIF = pd.DataFrame({'feature':name,\"VIF\":VIF_list})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7350a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr_df=df.corr()\n",
    "# 热力图\n",
    "sns.heatmap(corr_df)\n",
    "# 剔除相关性系数高于threshold的corr_drop\n",
    "threshold = 0.9\n",
    "upper = corr_df.where(np.triu(np.ones(corr_df.shape), k=1).astype(np.bool))\n",
    "corr_drop = [column for column in upper.columns if any(upper[column].abs() > threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c50943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi2检验\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "x, y = load_iris(return_X_y=True)\n",
    "\n",
    "x_new = SelectKBest(chi2, k=2).fit_transform(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86783997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#信息量\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.datasets import load_iris\n",
    "x, y = load_iris(return_X_y=True)\n",
    "mutual_info_classif(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff32968b",
   "metadata": {},
   "source": [
    "# Embedded methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e18c7bb",
   "metadata": {},
   "source": [
    "LASSO regression\n",
    "The features that are least predictive will shrink to zero in response to the L1 penalt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf966c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_new = SelectFromModel(LogisticRegression(penalty=\"l1\", C=0.1)).fit_transform(x,  y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045a3eb",
   "metadata": {},
   "source": [
    "Decision trees/Random forest \n",
    "The features chosen for splitting are picked to maximize decrease in Gini Impurity or Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ef570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import plot_importance\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "model = LGBMClassifier()\n",
    "model.fit(x, y)\n",
    "plot_importance(model,  max_num_features=20, figsize=(10,5),importance_type='split')\n",
    "plt.show()\n",
    "feature_importance = pd.DataFrame({\n",
    "        'feature': model.booster_.feature_name(),\n",
    "        'gain': model.booster_.feature_importance('gain'),\n",
    "        'split': model.booster_.feature_importance('split')\n",
    "    }).sort_values('gain',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5599360",
   "metadata": {},
   "source": [
    "# Wrapper feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea39fa8",
   "metadata": {},
   "source": [
    "穷举算法 (exhaustive search)，穷举算法是遍历所有可能的组合达到全局最优级，但是计算复杂度是2^n，一般是不太实际的算法。\n",
    "\n",
    "Greedy Forward Feature Construction\n",
    "前向搜索\n",
    "前向搜索说白了就是，每次增量地从剩余未选中的特征选出一个加入特征集中，待达到阈值或者 n 时，从所有的 F 中选出错误率最小的。过程如下：\n",
    "\n",
    "初始化特征集 F 为空。\n",
    "扫描 i 从 1 到 n 如果第 i 个特征不在 F 中，那么特征 i 和F 放在一起作为 F_i (即 F_i=F\\cup{i} )。 在只使用 F_i 中特征的情况下，利用交叉验证来得到 F_i 的错误率。\n",
    "从上步中得到的 n 个 F_i 中选出错误率最小的 F_i ,更新 F 为 F_i 。\n",
    "如果 F 中的特征数达到了 n 或者预定的阈值（如果有的话）， 那么输出整个搜索过程中最好的 ；若没达到，则转到 2，继续扫描。\n",
    "\n",
    "Greedy Backward Feature Elimination\n",
    "后向搜索\n",
    "既然有增量加，那么也会有增量减，后者称为后向搜索。先将 F 设置为 {1,2,...,n} ，然后每次删除一个特征，并评价，直到达到阈值或者为空，然后选择最佳的 F 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f321b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#递归特征消除法，返回特征选择后的数据\n",
    "#参数estimator为基模型\n",
    "#参数n_features_to_select为选择的特征个数\n",
    "RFE(estimator=LogisticRegression(), n_features_to_select=2).fit_transform(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb4410",
   "metadata": {},
   "source": [
    "# Split Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb938266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually a good idea to shuffle\n",
    "df = df.reindex(np.random.permutation(df.index)) \n",
    "\n",
    "mask = np.random.rand(len(df)) < 0.8\n",
    "trainDF = pd.DataFrame(df[mask])\n",
    "validationDF = pd.DataFrame(df[~mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66412f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#or\n",
    "from sklearn.model_selection import train_test_split\n",
    "Y_set = df2['name'].values\n",
    "X_set = df2.drop(labels= \"name\" , axis = 1).values\n",
    "\n",
    "# data spliting using 80:20 train test data ratio and randon seeding 6\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_set, Y_set, train_size=900,test_size=130, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f0f6b5",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528327e1",
   "metadata": {},
   "source": [
    "Continuous Values\n",
    "One common transformation is to normalize the inputs. It is sometimes valuable to normalize numeric inputs in a standard form so that the program can easily compare these two values. Consider if a friend told you that he received a 10-dollar discount. Is this a good deal? Maybe. But the cost is not normalized. If your friend purchased a car, the discount is not that good. If your friend bought lunch, this is an excellent discount!\n",
    "\n",
    "Percentages are a prevalent form of normalization. If your friend tells you they got 10% off, we know that this is a better discount than 5%. It does not matter how much the purchase price was. One widespread machine learning normalization is the Z-Score:\n",
    "\n",
    "z=x−μσ \n",
    "\n",
    "To calculate the Z-Score, you also need to calculate the mean(μ or  x¯ ) and the standard deviation (σ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "df2['mpg'] = zscore(df['mpg'])\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c286d",
   "metadata": {},
   "source": [
    "Encoding Categorical Values as Dummies\n",
    "The traditional means of encoding categorical values is to make them dummy variables. This technique is also called one-hot-encoding. Consider the following data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62254cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(['a','b','c','d'],prefix='area')\n",
    "print(dummies)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "df = pd.concat([df,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f261790",
   "metadata": {},
   "source": [
    "Target Encoding for Categoricals\n",
    "Target encoding is a popular technique for Kaggle competitions. Target encoding can sometimes increase the predictive power of a machine learning model. However, it also dramatically increases the risk of overfitting. Because of this risk, you must take care of using this method.\n",
    "\n",
    "Generally, target encoding can only be used on a categorical feature when the output of the machine learning model is numeric (regression).\n",
    "\n",
    "The concept of target encoding is straightforward. For each category, we calculate the average target value for that category. Then to encode, we substitute the percent corresponding to the category that the categorical value has. Unlike dummy variables, where you have a column for each category with target encoding, the program only needs a single column. In this way, target coding is more efficient than dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8991c6",
   "metadata": {},
   "source": [
    "# Shuffle and reindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c52d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(42) # Uncomment this line to get the same shuffle each time\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274957eb",
   "metadata": {},
   "source": [
    "# Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fa50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='name', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cedf746",
   "metadata": {},
   "source": [
    "# Grouping a Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e47781",
   "metadata": {},
   "source": [
    "Grouping is a typical operation on data sets. Structured Query Language (SQL) calls this operation a \"GROUP BY.\" Programmers use grouping to summarize data. Because of this, the summarization row count will usually shrink, and you cannot undo the grouping. Because of this loss of information, it is essential to keep your original data before the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d3d836",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df.groupby('cylinders')['mpg'].mean()#sum or count.\n",
    "#It might be useful to have these mean values as a dictionary.\n",
    "d = g.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655276c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
